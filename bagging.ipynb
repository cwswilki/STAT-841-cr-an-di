{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1302cf75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: /home/craig-wilkinson/.cache/kagglehub/datasets/agungpambudi/network-malware-detection-connection-analysis/versions/3\n",
      "             ts                 uid        id.orig_h  id.orig_p  \\\n",
      "0  1.538573e+09   Cu3Tieri43IPsyBO3  192.168.100.113    42789.0   \n",
      "1  1.538573e+09  Cbetl72NeXczaqQ8Lj  192.168.100.113    60546.0   \n",
      "2  1.538573e+09  CUmQWl2ZA2hrbNtohe  192.168.100.113    37320.0   \n",
      "3  1.538573e+09   C9oEZWtG35wx1Mqq5  192.168.100.113    51338.0   \n",
      "4  1.538573e+09  CbhqpU1oZZyrP7PE6i  192.168.100.113    60088.0   \n",
      "\n",
      "       id.resp_h  id.resp_p proto service  duration orig_bytes  ...  \\\n",
      "0  192.168.100.1       53.0   udp     dns         -          -  ...   \n",
      "1  192.168.100.1       53.0   udp     dns  0.001494         90  ...   \n",
      "2  192.168.100.1       53.0   udp     dns  5.005135         78  ...   \n",
      "3  192.168.100.1       53.0   udp     dns  0.001483         90  ...   \n",
      "4  192.168.100.1       53.0   udp     dns  5.038625        117  ...   \n",
      "\n",
      "  local_resp missed_bytes history orig_pkts  orig_ip_bytes resp_pkts  \\\n",
      "0          -          0.0       D       1.0           67.0       0.0   \n",
      "1          -          0.0      Dd       2.0          146.0       2.0   \n",
      "2          -          0.0       D       2.0          134.0       0.0   \n",
      "3          -          0.0      Dd       2.0          146.0       2.0   \n",
      "4          -          0.0      Dd       3.0          201.0       2.0   \n",
      "\n",
      "   resp_ip_bytes  tunnel_parents   label  detailed-label  \n",
      "0            0.0               -  Benign               -  \n",
      "1          146.0               -  Benign               -  \n",
      "2            0.0               -  Benign               -  \n",
      "3          146.0               -  Benign               -  \n",
      "4          198.0               -  Benign               -  \n",
      "\n",
      "[5 rows x 23 columns]\n"
     ]
    }
   ],
   "source": [
    "RANDOM_STATE = 2025\n",
    "TEST_PCT = 0.5\n",
    "SUBSAMPLE_COUNT = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2333ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"agungpambudi/network-malware-detection-connection-analysis\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)\n",
    "\n",
    "\n",
    "RELOAD_DATA = False\n",
    "if not RELOAD_DATA:\n",
    "  try:\n",
    "    print(df.head())\n",
    "  except Exception as e:\n",
    "    print(\"No dataframe.  Loading data...\")\n",
    "    RELOAD_DATA=True\n",
    "if RELOAD_DATA:\n",
    "  dataframes = []\n",
    "  import os\n",
    "  for dirname, _, filenames in os.walk(path):\n",
    "    for index, filename in enumerate(filenames):\n",
    "      full_path = os.path.join(dirname, filename)\n",
    "      print(f\"Using file: {full_path}\")\n",
    "      dataframes.append(pd.read_csv(full_path, sep =\"|\"))\n",
    "  df = pd.concat(dataframes, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e29e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "SKIPPED_COLUMNS = [\n",
    "  'ts', 'uid', 'id.orig_h', 'id.resp_h', 'tunnel_parents', 'detailed-label']\n",
    "ONE_HOT_COLUMNS = ['proto', 'service', 'conn_state', 'local_orig', 'local_resp', 'history', ]\n",
    "NUMERIC_COLUMNS = [\n",
    "   'id.orig_p', 'id.resp_p', #??\n",
    "   'duration', 'orig_bytes',\n",
    "     'resp_bytes', 'missed_bytes', \n",
    "   'orig_pkts', 'orig_ip_bytes', 'resp_pkts', 'resp_ip_bytes',\n",
    "]\n",
    "LABEL_COLUMN = ['label']\n",
    "\n",
    "def process_data(df):\n",
    "  df = df[ONE_HOT_COLUMNS + NUMERIC_COLUMNS + LABEL_COLUMN]\n",
    "\n",
    "  if SUBSAMPLE_COUNT:\n",
    "    df = df.sample(n=SUBSAMPLE_COUNT, random_state=42).copy()\n",
    "  for col in NUMERIC_COLUMNS:\n",
    "    df.loc[:, col] = pd.to_numeric(df[col], errors='coerce')\n",
    "    df.loc[:, col] = df[col].fillna(0)\n",
    "\n",
    "  df_test = df.sample(frac=TEST_PCT)\n",
    "  features_test = df_test.drop(columns=LABEL_COLUMN)\n",
    "  y_test = pd.DataFrame()\n",
    "  y_test['label'] = np.where(df_test[LABEL_COLUMN[0]] == 'Benign', 1, 0)\n",
    "  \n",
    "  df_train = df.drop(df_test.index)\n",
    "  features_train = df_train.drop(columns=LABEL_COLUMN)\n",
    "  y_train = pd.DataFrame()\n",
    "  \n",
    "  #y_train['label'] = (1 if df_train[LABEL_COLUMN[0]] == 'Benign' else 0)\n",
    "  y_train['label'] = np.where(df_train[LABEL_COLUMN[0]] == 'Benign', 1, 0)\n",
    "  \n",
    "  print(features_train.head())\n",
    "  print(y_train.head())\n",
    "  print(features_test.head())\n",
    "  print(y_test.head())\n",
    "  return features_train, y_train, features_test, y_test\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "035a5329",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_262875/42738861.py:18: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  sampled_df.loc[:, col] = sampled_df[col].fillna(0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         proto service conn_state local_orig local_resp history  id.orig_p  \\\n",
      "21229140   tcp       -         S0          -          -       S    58968.0   \n",
      "24816257   tcp       -         S0          -          -       S    39102.0   \n",
      "19037749   tcp       -         S0          -          -       S    48178.0   \n",
      "5783878    tcp       -         S0          -          -       S    42564.0   \n",
      "23373406   tcp       -     RSTOS0          -          -       I    55982.0   \n",
      "\n",
      "          id.resp_p  duration orig_bytes resp_bytes  missed_bytes  orig_pkts  \\\n",
      "21229140       23.0       0.0        0.0        0.0           0.0        1.0   \n",
      "24816257       23.0       0.0        0.0        0.0           0.0        1.0   \n",
      "19037749       23.0  3.140466        0.0        0.0           0.0        3.0   \n",
      "5783878        23.0  0.000002        0.0        0.0           0.0        2.0   \n",
      "23373406       80.0  2.688476        0.0        0.0           0.0        2.0   \n",
      "\n",
      "          orig_ip_bytes  resp_pkts  resp_ip_bytes  \n",
      "21229140           60.0        0.0            0.0  \n",
      "24816257           60.0        0.0            0.0  \n",
      "19037749          180.0        0.0            0.0  \n",
      "5783878           120.0        0.0            0.0  \n",
      "23373406           80.0        0.0            0.0  \n",
      "   label\n",
      "0      1\n",
      "1      1\n",
      "2      1\n",
      "3      0\n",
      "4      0\n",
      "         proto service conn_state local_orig local_resp history  id.orig_p  \\\n",
      "12225234   tcp       -         S0          -          -       S    24587.0   \n",
      "259339     tcp       -        OTH          -          -       C     2896.0   \n",
      "7328677    udp       -         S0          -          -       D    43763.0   \n",
      "18016638   tcp       -         S0          -          -       S    40842.0   \n",
      "24946108   tcp       -         S0          -          -       S    52040.0   \n",
      "\n",
      "          id.resp_p duration orig_bytes resp_bytes  missed_bytes  orig_pkts  \\\n",
      "12225234       23.0      0.0        0.0        0.0           0.0        1.0   \n",
      "259339      62336.0      0.0        0.0        0.0           0.0        0.0   \n",
      "7328677     32386.0      0.0        0.0        0.0           0.0        1.0   \n",
      "18016638       23.0      0.0        0.0        0.0           0.0        1.0   \n",
      "24946108       23.0      0.0        0.0        0.0           0.0        1.0   \n",
      "\n",
      "          orig_ip_bytes  resp_pkts  resp_ip_bytes  \n",
      "12225234           40.0        0.0            0.0  \n",
      "259339              0.0        0.0            0.0  \n",
      "7328677            40.0        0.0            0.0  \n",
      "18016638           60.0        0.0            0.0  \n",
      "24946108           60.0        0.0            0.0  \n",
      "   label\n",
      "0      0\n",
      "1      0\n",
      "2      1\n",
      "3      1\n",
      "4      1\n"
     ]
    }
   ],
   "source": [
    "df_features_train, df_y_train, df_features_test, df_y_test = process_data(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be9ca443",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/craig-wilkinson/miniconda3/lib/python3.13/site-packages/sklearn/ensemble/_bagging.py:930: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "# @title Question 1 - b\n",
    "from numpy.random.mtrand import f\n",
    "import sklearn\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "def train_bagging(df_features_train, df_y_train, max_depth=2):\n",
    "\n",
    "  preprocessor = make_column_transformer(\n",
    "      (OneHotEncoder(handle_unknown='ignore'), ONE_HOT_COLUMNS),\n",
    "      remainder='passthrough'\n",
    "  )\n",
    "  tree_classifier = sklearn.tree.DecisionTreeClassifier(max_depth=max_depth)\n",
    "\n",
    "  bagging_classifier = make_pipeline(\n",
    "      preprocessor,\n",
    "      sklearn.ensemble.BaggingClassifier(\n",
    "          estimator=tree_classifier,\n",
    "          n_estimators=500,\n",
    "          max_samples=0.5,\n",
    "          bootstrap=False,\n",
    "          n_jobs=-1,\n",
    "          random_state=RANDOM_STATE)\n",
    "  )\n",
    "  bagging_classifier.fit(df_features_train, df_y_train)\n",
    "\n",
    "  return bagging_classifier\n",
    "\n",
    "bagging_classifier = train_bagging(df_features_train, df_y_train, max_depth=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a24af1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('columntransformer',\n",
      "                 ColumnTransformer(remainder='passthrough',\n",
      "                                   transformers=[('onehotencoder',\n",
      "                                                  OneHotEncoder(handle_unknown='ignore'),\n",
      "                                                  ['proto', 'service',\n",
      "                                                   'conn_state', 'local_orig',\n",
      "                                                   'local_resp',\n",
      "                                                   'history'])])),\n",
      "                ('baggingclassifier',\n",
      "                 BaggingClassifier(bootstrap=False,\n",
      "                                   estimator=DecisionTreeClassifier(max_depth=5),\n",
      "                                   max_samples=0.5, n_estimators=500, n_jobs=-1,\n",
      "                                   random_state=2025))])\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99    259945\n",
      "           1       0.97      1.00      0.98    140055\n",
      "\n",
      "    accuracy                           0.99    400000\n",
      "   macro avg       0.98      0.99      0.99    400000\n",
      "weighted avg       0.99      0.99      0.99    400000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "print(bagging_classifier)\n",
    "\n",
    "def compute_metrics(classifier, df_features, df_y):\n",
    "  results = classifier.predict(df_features)\n",
    "\n",
    "  predictions = classifier.predict(df_features)\n",
    "  \n",
    "  print(classification_report(df_y, predictions))  \n",
    "\n",
    "\n",
    "compute_metrics(bagging_classifier, df_features_test, df_y_test)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
